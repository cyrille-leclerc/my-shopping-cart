integrations:
  # elasticsearch_exporter:
  #   address: http://localhost:9200
  #   enabled: true
  node_exporter:
    enabled: true
    disable_collectors:
      - thermal # disable on Apple Silicon
    metric_relabel_configs:
      - action: keep
        regex: node_load1|node_filesystem_avail_bytes|node_disk_read_bytes_total|node_network_receive_drop_total|node_memory_compressed_bytes|node_memory_total_bytes|node_memory_wired_bytes|node_disk_written_bytes_total|node_memory_purgeable_bytes|node_textfile_scrape_error|node_memory_Cached_bytes|node_memory_Slab_bytes|node_memory_internal_bytes|node_network_transmit_packets_total|node_network_transmit_drop_total|node_disk_io_time_weighted_seconds_total|node_load5|node_filesystem_files|node_network_transmit_errs_total|node_memory_Buffers_bytes|node_network_receive_bytes_total|node_filesystem_size_bytes|node_load15|node_cpu_seconds_total|node_vmstat_pgmajfault|node_filesystem_files_free|node_network_receive_errs_total|node_network_receive_packets_total|node_memory_MemFree_bytes|node_memory_MemTotal_bytes|node_network_transmit_bytes_total|node_disk_io_time_seconds_total|node_uname_info|node_filesystem_readonly|node_memory_MemAvailable_bytes
        source_labels:
          - __name__
    relabel_configs:
      - replacement: cyrille-le-clerc-macbook
        source_labels:
          - agent_hostname
        target_label: instance
      - replacement: cyrillerclaptop
        source_labels:
          - agent_hostname
        target_label: instance
      - replacement: integrations/macos-node
        source_labels:
          - agent_hostname
        target_label: job
  prometheus_remote_write:
    - basic_auth:
        password: ${PROMETHEUS_PASSWORD}
        username: ${PROMETHEUS_USERNAME}
      url: ${PROMETHEUS_URL}
logs:
  configs:
    - clients:
        - basic_auth:
            password: ${LOKI_PASSWORD}
            username: ${LOKI_USERNAME}
          url: ${LOKI_URL}
      name: integrations
      positions:
        filename: /tmp/positions.yaml
      scrape_configs:
        - job_name: integrations/node_exporter_direct_scrape
          pipeline_stages:
            - multiline:
                firstline: ^([\w]{3} )?[\w]{3} +[\d]+ [\d]+:[\d]+:[\d]+|[\w]{4}-[\w]{2}-[\w]{2}
                  [\w]{2}:[\w]{2}:[\w]{2}(?:[+-][\w]{2})?
            - regex:
                expression: (?P<timestamp>([\w]{3} )?[\w]{3} +[\d]+
                  [\d]+:[\d]+:[\d]+|[\w]{4}-[\w]{2}-[\w]{2}
                  [\w]{2}:[\w]{2}:[\w]{2}(?:[+-][\w]{2})?) (?P<hostname>\S+)
                  (?P<sender>.+?)\[(?P<pid>\d+)\]:? (?P<message>(?s:.*))$
            - labels:
                ? hostname
                ? pid
                ? sender
            - match:
                selector: '{sender!="", pid!=""}'
                stages:
                  - template:
                      source: message
                      template: "{{.sender }}[{{.pid}}]: {{ .message }}"
                  - labeldrop:
                      - pid
                  - output:
                      source: message
          static_configs:
            - labels:
                __path__: /var/log/*.log
                instance: cyrillerclaptop
                job: integrations/macos-node
              targets:
                - localhost
        - job_name: my_shopping_cart_frontend
          pipeline_stages:
            # 2022-09-08 17:51:20.963  INFO 22952 --- [main] c.m.ecommerce.EcommerceApplication       : Starting EcommerceApplication using Java 11.0.11 on cyrillerclaptop with PID 22952 (/Users/cyrilleleclerc/git/cyrille-leclerc/my-shopping-cart/frontend-java/target/frontend-1.0-SNAPSHOT.jar started by cyrilleleclerc in /Users/cyrilleleclerc/git/cyrille-leclerc/my-shopping-cart/frontend-java)
            - multiline:
                firstline: ^\d{4}-\d{1,2}-\d{1,2} \d{1,2}:\d{1,2}:\d{1,2}.\d{3}\s
            - regex:
                expression: ^(?P<timestamp>\d{4}-\d{1,2}-\d{1,2} \d{1,2}:\d{1,2}:\d{1,2}.\d{3})\s+(?P<severity_text>[^\s]+)\s+(?P<process_id>\d+).*?\[\s+(?P<thread_name>.*)\]\s+(?P<instrumentation_scope>.*)\s+:\s+(?P<message>(?:.*))
            - timestamp:
                source: timestamp
                format: '2022-05-31 10:00:29.315'  
            - output:
                source: message
          static_configs:
            - labels:
                #__path__: /usr/local/var/log/my-shopping-cart/*.log
                #__path_exclude__: "/usr/local/var/log/my-shopping-cart/*_gc.log"
                __path__: /usr/local/var/log/my-shopping-cart/frontend.log
                instance: cyrillerclaptop
                job: my_shopping_cart_frontend
              targets:
                - localhost
      target_config:
        sync_period: 10s
metrics:
  configs:
    - name: integrations
      remote_write:
        - basic_auth:
            password: ${PROMETHEUS_PASSWORD}
            username: ${PROMETHEUS_USERNAME}
          url: ${PROMETHEUS_URL}
  global:
    scrape_interval: 60s
  wal_directory: /tmp/grafana-agent-wal
traces:
  configs:
  - name: default
    remote_write:
      - endpoint: ${TEMPO_ENDPOINT}
        basic_auth:
          username: ${TEMPO_USERNAME}
          password: ${TEMPO_PASSWORD}
    # service_graphs configures processing of traces for building service graphs in
    # the form of prometheus metrics. The generated metrics represent edges between
    # nodes in the graph. Nodes are represented by `client` and `server` labels.
    #
    #  e.g. tempo_service_graph_request_total{client="app", server="db"} 20
    #
    # Service graphs works by inspecting spans and looking for the tag `span.kind`.
    # If it finds the span kind to be client or server, it stores the request in a
    # local in-memory store.
    #
    # That request waits until its corresponding client or server pair span is
    # processed or until the maximum waiting time has passed.
    # When either of those conditions is reached, the request is processed and
    # removed from the local store. If the request is complete by that time, it'll
    # be recorded as an edge in the graph.
    #
    # Service graphs supports multi-agent deployments, allowing to group all spans
    # of a trace in the same agent by load balancing the spans by trace ID between
    # the instances.
    # * To make use of this feature, check load_balancing above *
    service_graphs:
      enabled: true

      # configures the time the processor will wait since a span is consumed until
      # it's considered expired if its paired has not been processed.
      #
      # increasing the waiting time will increase the percentage of paired spans.
      # retaining unpaired spans for longer will make reaching max_items more likely.
      #[ wait: <duration> | default = "10s"]

      # configures the max amount of edges that will be stored in memory.
      #
      # spans that arrive to the processor that do not pair with an already
      # processed span are dropped.
      #
      # a higher max number of items increases the max throughput of processed spans
      # with a higher memory consumption.
      #[ max_items: <integer> | default = 10_000 ]
      
      # configures the number of workers that will process completed edges concurrently.
      # as edges are completed, they get queued to be collected as metrics for the graph.
      #[ workers: <integer> | default = 10]
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: '127.0.0.1:4318'
    # spanmetrics supports aggregating Request, Error and Duration (R.E.D) metrics
    # from span data.
    #
    # spanmetrics generates two metrics from spans and uses remote_write or
    # OpenTelemetry Prometheus exporters to serve the metrics locally.
    #
    # In order to use the remote_write exporter, you have to configure a Prometheus
    # instance in the Agent and pass its name to the `metrics_instance` field.
    #
    # If you want to use the OpenTelemetry Prometheus exporter, you have to
    # configure handler_endpoint and then scrape that endpoint.
    #
    # The first generated metric is `calls`, a counter to compute requests.
    # The second generated metric is `latency`, a histogram to compute the
    # operation's duration.
    #
    # If you want to rename the generated metrics, you can configure the `namespace`
    # option of prometheus exporter.
    #
    # This is an experimental feature of Opentelemetry-Collector and the behavior
    # may change in the future.
    spanmetrics:
      # latency_histogram_buckets and dimensions are the same as the configs in
      # spanmetricsprocessor.
      #[ latency_histogram_buckets: <spanmetricsprocessor.latency_histogram_buckets> ]
      #[ dimensions: <spanmetricsprocessor.dimensions> ]
      # const_labels are labels that will always get applied to the exported
      # metrics.
      #const_labels:
      #  [ <string>: <string>... ]
      # Metrics are namespaced to `traces_spanmetrics` by default.
      # They can be further namespaced, i.e. `{namespace}_traces_spanmetrics`
      #[ namespace: <string> ]
      # metrics_instance is the metrics instance used to remote write metrics.
      #[ metrics_instance: <string> ]
      # handler_endpoint defines the endpoint where the OTel prometheus exporter will be exposed.
      #[ handler_endpoint: <string> ]
